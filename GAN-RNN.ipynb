{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "My objevtive for the machine learning project is to create a Recurrent Neural Network (RNN) that can generate (somewhat) legible poetry based on a collection of poems with a GAN external network to optimize the RNN potential. To do so, I will take a kaggle dataset with 500+ poems written from the reniassance and modern era of poetry to be used as the 'real' data for the discriminator.\n",
    "\n",
    "Tools:\n",
    "Libraries include pandas, numpy, keras.preprocessing for tokenizer (discussed below), GloVe dictionary (below), and keras.layers/models and the like for neural network model architecture and execution. \n",
    "\n",
    "Various hygiene methods are required to standardize each poem into the same length, as well as adding padding for poems less in length. Instead of feeding in actual words, I will encode each word into a tokenizer, so integers are fed into the network rather than words. Further, to better contend with writing legible poetry, I use feature engineering from https://nlp.stanford.edu/projects/glove/ to encode words to higher dimensional space. Words with similar meaning should have a similar vector space, for example. \n",
    "\n",
    "Both the generator and discriminator have RNN structures, including one LSTM layer to predict the next word based on the series of words prior in sequence. The discriminator will take samples from our real poems and full generated poems to try and classify real from fake. \n",
    "\n",
    "\n",
    "link to data : https://www.kaggle.com/ishnoor/poetry-analysis-with-machine-learning\n",
    "\n",
    "References: some hygiene steps came from https://www.kaggle.com/hsankesara/mr-poet and some GAN framework coding came from https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.5-introduction-to-gans.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "poems = pd.read_csv(\"all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding character length column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samburtch/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "poems['length'] = 0\n",
    "for i in range(len(poems)):\n",
    "    poems['length'][i] = len(poems['content'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data by deleting null entries and non-poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552\n",
      "536\n",
      "518\n",
      "465\n"
     ]
    }
   ],
   "source": [
    "poems = poems.sort_values(by='length') #Sort by length of poem\n",
    "poems = poems[14:len(poems)-5] # Delete tails on both sides\n",
    "poems = poems[poems['content'].str.contains('Published')==False]# Eliminate non-poems with 'Published'\n",
    "print(len(poems))\n",
    "poems = poems[poems['content'].str.contains('from Selected Poems')==False]# Eliminate non-poems with 'from Selected Poems'\n",
    "print(len(poems))\n",
    "poems = poems[poems['content'].str.contains('Collected Poems')==False]# Eliminate non-poems with 'from Collected Poems'\n",
    "print(len(poems))\n",
    "#Eliminate where poem is just intro\n",
    "for ind, row in poems.iterrows():\n",
    "    if row['author'] in row['content'].upper() or str(row['poem name']) in row['content'][:40]:\n",
    "        poems = poems.drop([ind])\n",
    "print(len(poems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hygiene: only poems between 100 & 1000 in character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_poems = len(poems)\n",
    "poem = poems['content'][:num_poems]\n",
    "poem = poem[poems['length'] > 100]\n",
    "poem = poem[poems['length'] < 1000]\n",
    "poem = poem.reset_index(drop=True)\n",
    "X = poem\n",
    "num_poems = len(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vocab size and word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ''\n",
    "for i in range(num_poems):\n",
    "    temp += poem[i] + ' '\n",
    "poem = temp\n",
    "\n",
    "import re\n",
    "#poem = re.sub(' +',' ',poem)\n",
    "poem = poem.lower()\n",
    "poem = re.findall(r'[\\w]+|[\\'!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]',poem)\n",
    "words = list(set(poem))\n",
    "vocab_size = len(words)\n",
    "#print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count                                                   349\n",
      "unique                                                  311\n",
      "top       When I was fair and young, then favor graced m...\n",
      "freq                                                      3\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The fog comes\\r\\non little cat feet.\\r\\n\\r\\nIt sits looking\\r\\nover harbor and city\\r\\non silent haunches\\r\\nand then moves on.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    X[i] = X[i].replace(\"\\r\\n\",\" \")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Convert words to integers (tokenizer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samburtch/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import  Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer( num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.texts_to_sequences(X)\n",
    "maxlen = 0\n",
    "for i in text:\n",
    "    if len(i) > maxlen:\n",
    "        maxlen = len(i)\n",
    "text = pad_sequences(text, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxwords = len(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map words to 50-dim vector (embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((maxwords+1,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove.6B.50d.txt') as f:\n",
    "    for line in f:\n",
    "        l = line.split()\n",
    "        if l[0] in word_dict:\n",
    "            indx = word_dict[l[0]]\n",
    "            for i in range(50):\n",
    "                embedding_matrix[indx][i] = l[i+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 349 x 177 x 50 X_train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros((349,177,50),dtype='float32')\n",
    "for indp, poem in enumerate(text):\n",
    "    for indw, word in enumerate(poem):\n",
    "        x_train[indp,indw,:] = embedding_matrix[word]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network \n",
    "<img src=\"gan.png\">\n",
    "GAN networks are two separate networks playing against each other. The Generator gets random noise and creates output, attempting to try and fool the discriminator into thinking the generated output is real data, poems in our case. The discriminators only job is to decide if the input was real or fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "num_steps = 177\n",
    "#hidden_size = 350\n",
    "feature_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = Input(shape=(num_steps,1))\n",
    "\n",
    "x = LSTM(feature_dim, return_sequences=True, recurrent_dropout=0.2)(generator_input)\n",
    "x = LSTM(feature_dim, return_sequences=True, recurrent_dropout=0.2)(x)\n",
    "generator = Model(generator_input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = Input(shape=(num_steps,feature_dim))\n",
    "\n",
    "x = LSTM(feature_dim, return_sequences=True, recurrent_dropout=0.2)(discriminator_input) #return_sequences=True,\n",
    "x = LSTM(feature_dim, recurrent_dropout=0.2)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = Model(discriminator_input, x)\n",
    "\n",
    "discriminator_optimizer = RMSprop(lr=0.0001, clipvalue=1.0) #decay=1e-8\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "# Set discriminator weights to non-trainable\n",
    "# (will only apply to the `gan` model)\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = Input(shape=(num_steps,1))\n",
    "gen_output = generator(gan_input)\n",
    "gan_output = discriminator(gen_output)\n",
    "gan = Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = RMSprop(lr=0.001, clipvalue=1.0) #decay=1e-8\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samburtch/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 0: 0.6920873\n",
      "generator loss at step 0: 0.6966387\n",
      "discriminator loss at step 10: 0.8458086\n",
      "generator loss at step 10: 0.48831588\n",
      "discriminator loss at step 20: 0.84898806\n",
      "generator loss at step 20: 0.47552508\n",
      "discriminator loss at step 30: 0.80207574\n",
      "generator loss at step 30: 0.5421148\n",
      "discriminator loss at step 40: 0.7531474\n",
      "generator loss at step 40: 0.60654247\n",
      "discriminator loss at step 50: 0.74729776\n",
      "generator loss at step 50: 0.6333684\n",
      "discriminator loss at step 60: 0.7485031\n",
      "generator loss at step 60: 0.60230625\n",
      "discriminator loss at step 70: 0.78724843\n",
      "generator loss at step 70: 0.56337565\n",
      "discriminator loss at step 80: 0.77708435\n",
      "generator loss at step 80: 0.5739377\n",
      "discriminator loss at step 90: 0.7511819\n",
      "generator loss at step 90: 0.62389386\n",
      "discriminator loss at step 100: 0.6987225\n",
      "generator loss at step 100: 0.6850028\n",
      "discriminator loss at step 110: 0.6954695\n",
      "generator loss at step 110: 0.7050105\n",
      "discriminator loss at step 120: 0.7308098\n",
      "generator loss at step 120: 0.670498\n",
      "discriminator loss at step 130: 0.7243434\n",
      "generator loss at step 130: 0.6753004\n",
      "discriminator loss at step 140: 0.69192183\n",
      "generator loss at step 140: 0.7401371\n",
      "discriminator loss at step 150: 0.6815978\n",
      "generator loss at step 150: 0.7256683\n",
      "discriminator loss at step 160: 0.71499443\n",
      "generator loss at step 160: 0.6743074\n",
      "discriminator loss at step 170: 0.717829\n",
      "generator loss at step 170: 0.6599679\n",
      "discriminator loss at step 180: 0.7465525\n",
      "generator loss at step 180: 0.6298836\n",
      "discriminator loss at step 190: 0.73666924\n",
      "generator loss at step 190: 0.63014996\n",
      "discriminator loss at step 200: 0.7318703\n",
      "generator loss at step 200: 0.66413814\n",
      "discriminator loss at step 210: 0.7190157\n",
      "generator loss at step 210: 0.6577157\n",
      "discriminator loss at step 220: 0.6983007\n",
      "generator loss at step 220: 0.68208927\n",
      "discriminator loss at step 230: 0.6837403\n",
      "generator loss at step 230: 0.71785134\n",
      "discriminator loss at step 240: 0.73889816\n",
      "generator loss at step 240: 0.6845989\n",
      "discriminator loss at step 250: 0.72495264\n",
      "generator loss at step 250: 0.681005\n",
      "discriminator loss at step 260: 0.6757639\n",
      "generator loss at step 260: 0.727555\n",
      "discriminator loss at step 270: 0.67270005\n",
      "generator loss at step 270: 0.74727684\n",
      "discriminator loss at step 280: 0.6635639\n",
      "generator loss at step 280: 0.7703389\n",
      "discriminator loss at step 290: 0.64085543\n",
      "generator loss at step 290: 0.81827176\n",
      "discriminator loss at step 300: 0.62336075\n",
      "generator loss at step 300: 0.84875363\n",
      "discriminator loss at step 310: 0.6535796\n",
      "generator loss at step 310: 0.79215366\n",
      "discriminator loss at step 320: 0.69367987\n",
      "generator loss at step 320: 0.741618\n",
      "discriminator loss at step 330: 0.72322977\n",
      "generator loss at step 330: 0.65271413\n",
      "discriminator loss at step 340: 0.710327\n",
      "generator loss at step 340: 0.66574574\n",
      "discriminator loss at step 350: 0.71565104\n",
      "generator loss at step 350: 0.6584896\n",
      "discriminator loss at step 360: 0.6641943\n",
      "generator loss at step 360: 0.7263491\n",
      "discriminator loss at step 370: 0.65998286\n",
      "generator loss at step 370: 0.7708156\n",
      "discriminator loss at step 380: 0.6692912\n",
      "generator loss at step 380: 0.7554871\n",
      "discriminator loss at step 390: 0.7069189\n",
      "generator loss at step 390: 0.65857244\n",
      "discriminator loss at step 400: 0.7380713\n",
      "generator loss at step 400: 0.6184586\n",
      "discriminator loss at step 410: 0.756754\n",
      "generator loss at step 410: 0.60712385\n",
      "discriminator loss at step 420: 0.7295871\n",
      "generator loss at step 420: 0.64156353\n",
      "discriminator loss at step 430: 0.7268863\n",
      "generator loss at step 430: 0.6689848\n",
      "discriminator loss at step 440: 0.7153735\n",
      "generator loss at step 440: 0.66884005\n",
      "discriminator loss at step 450: 0.71518594\n",
      "generator loss at step 450: 0.66661954\n",
      "discriminator loss at step 460: 0.7231058\n",
      "generator loss at step 460: 0.66839284\n",
      "discriminator loss at step 470: 0.70622194\n",
      "generator loss at step 470: 0.69594896\n",
      "discriminator loss at step 480: 0.6954644\n",
      "generator loss at step 480: 0.6918655\n",
      "discriminator loss at step 490: 0.71211386\n",
      "generator loss at step 490: 0.69899124\n",
      "discriminator loss at step 500: 0.69495595\n",
      "generator loss at step 500: 0.7155488\n",
      "discriminator loss at step 510: 0.6978122\n",
      "generator loss at step 510: 0.70337236\n",
      "discriminator loss at step 520: 0.70018214\n",
      "generator loss at step 520: 0.7147841\n",
      "discriminator loss at step 530: 0.6995181\n",
      "generator loss at step 530: 0.70922947\n",
      "discriminator loss at step 540: 0.6900774\n",
      "generator loss at step 540: 0.7359577\n",
      "discriminator loss at step 550: 0.6972333\n",
      "generator loss at step 550: 0.7124151\n",
      "discriminator loss at step 560: 0.7034298\n",
      "generator loss at step 560: 0.7091618\n",
      "discriminator loss at step 570: 0.68329227\n",
      "generator loss at step 570: 0.7322031\n",
      "discriminator loss at step 580: 0.6608052\n",
      "generator loss at step 580: 0.781029\n",
      "discriminator loss at step 590: 0.6640688\n",
      "generator loss at step 590: 0.8304895\n",
      "discriminator loss at step 600: 0.6523476\n",
      "generator loss at step 600: 0.7968799\n",
      "discriminator loss at step 610: 0.6721072\n",
      "generator loss at step 610: 0.7550144\n",
      "discriminator loss at step 620: 0.728665\n",
      "generator loss at step 620: 0.6805489\n",
      "discriminator loss at step 630: 0.7136364\n",
      "generator loss at step 630: 0.6785904\n",
      "discriminator loss at step 640: 0.69398326\n",
      "generator loss at step 640: 0.69169396\n",
      "discriminator loss at step 650: 0.6880811\n",
      "generator loss at step 650: 0.7141711\n",
      "discriminator loss at step 660: 0.6715065\n",
      "generator loss at step 660: 0.7499835\n",
      "discriminator loss at step 670: 0.64685774\n",
      "generator loss at step 670: 0.80935687\n",
      "discriminator loss at step 680: 0.66519564\n",
      "generator loss at step 680: 0.7486839\n",
      "discriminator loss at step 690: 0.6920849\n",
      "generator loss at step 690: 0.7101717\n",
      "discriminator loss at step 700: 0.6815793\n",
      "generator loss at step 700: 0.7238455\n",
      "discriminator loss at step 710: 0.67519534\n",
      "generator loss at step 710: 0.7538961\n",
      "discriminator loss at step 720: 0.6545771\n",
      "generator loss at step 720: 0.77271813\n",
      "discriminator loss at step 730: 0.65494776\n",
      "generator loss at step 730: 0.770951\n",
      "discriminator loss at step 740: 0.7193735\n",
      "generator loss at step 740: 0.6526971\n",
      "discriminator loss at step 750: 0.7136797\n",
      "generator loss at step 750: 0.6583302\n",
      "discriminator loss at step 760: 0.71025676\n",
      "generator loss at step 760: 0.6968862\n",
      "discriminator loss at step 770: 0.6912476\n",
      "generator loss at step 770: 0.7030231\n",
      "discriminator loss at step 780: 0.696242\n",
      "generator loss at step 780: 0.70992774\n",
      "discriminator loss at step 790: 0.6873652\n",
      "generator loss at step 790: 0.7165785\n",
      "discriminator loss at step 800: 0.6916429\n",
      "generator loss at step 800: 0.7204665\n",
      "discriminator loss at step 810: 0.6933201\n",
      "generator loss at step 810: 0.7227895\n",
      "discriminator loss at step 820: 0.6959629\n",
      "generator loss at step 820: 0.7275365\n",
      "discriminator loss at step 830: 0.6935226\n",
      "generator loss at step 830: 0.73050857\n",
      "discriminator loss at step 840: 0.69319654\n",
      "generator loss at step 840: 0.72517484\n",
      "discriminator loss at step 850: 0.69108605\n",
      "generator loss at step 850: 0.72985\n",
      "discriminator loss at step 860: 0.6891015\n",
      "generator loss at step 860: 0.72374785\n",
      "discriminator loss at step 870: 0.6934886\n",
      "generator loss at step 870: 0.7366106\n",
      "discriminator loss at step 880: 0.6915515\n",
      "generator loss at step 880: 0.72901124\n",
      "discriminator loss at step 890: 0.6889521\n",
      "generator loss at step 890: 0.73745716\n",
      "discriminator loss at step 900: 0.6931385\n",
      "generator loss at step 900: 0.7341988\n",
      "discriminator loss at step 910: 0.68827534\n",
      "generator loss at step 910: 0.73284566\n",
      "discriminator loss at step 920: 0.6905186\n",
      "generator loss at step 920: 0.73946726\n",
      "discriminator loss at step 930: 0.6956888\n",
      "generator loss at step 930: 0.7378247\n",
      "discriminator loss at step 940: 0.6896895\n",
      "generator loss at step 940: 0.7426189\n",
      "discriminator loss at step 950: 0.6931423\n",
      "generator loss at step 950: 0.73904073\n",
      "discriminator loss at step 960: 0.6925386\n",
      "generator loss at step 960: 0.73949313\n",
      "discriminator loss at step 970: 0.6943449\n",
      "generator loss at step 970: 0.74061\n",
      "discriminator loss at step 980: 0.68834955\n",
      "generator loss at step 980: 0.7457433\n",
      "discriminator loss at step 990: 0.68593913\n",
      "generator loss at step 990: 0.74678075\n",
      "discriminator loss at step 1000: 0.6933951\n",
      "generator loss at step 1000: 0.7421157\n",
      "discriminator loss at step 1010: 0.6924946\n",
      "generator loss at step 1010: 0.74247396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 1020: 0.6948181\n",
      "generator loss at step 1020: 0.7397195\n",
      "discriminator loss at step 1030: 0.688212\n",
      "generator loss at step 1030: 0.743137\n",
      "discriminator loss at step 1040: 0.6941956\n",
      "generator loss at step 1040: 0.74120843\n",
      "discriminator loss at step 1050: 0.690996\n",
      "generator loss at step 1050: 0.73967105\n",
      "discriminator loss at step 1060: 0.6939238\n",
      "generator loss at step 1060: 0.737608\n",
      "discriminator loss at step 1070: 0.6950324\n",
      "generator loss at step 1070: 0.7433268\n",
      "discriminator loss at step 1080: 0.6946225\n",
      "generator loss at step 1080: 0.74216473\n",
      "discriminator loss at step 1090: 0.6896813\n",
      "generator loss at step 1090: 0.7444212\n",
      "discriminator loss at step 1100: 0.6792675\n",
      "generator loss at step 1100: 0.7422532\n",
      "discriminator loss at step 1110: 0.6973547\n",
      "generator loss at step 1110: 0.74047697\n",
      "discriminator loss at step 1120: 0.69042313\n",
      "generator loss at step 1120: 0.7405403\n",
      "discriminator loss at step 1130: 0.6918121\n",
      "generator loss at step 1130: 0.7438568\n",
      "discriminator loss at step 1140: 0.6894271\n",
      "generator loss at step 1140: 0.74592555\n",
      "discriminator loss at step 1150: 0.6906905\n",
      "generator loss at step 1150: 0.7381676\n",
      "discriminator loss at step 1160: 0.6882469\n",
      "generator loss at step 1160: 0.74407244\n",
      "discriminator loss at step 1170: 0.6707139\n",
      "generator loss at step 1170: 0.74643964\n",
      "discriminator loss at step 1180: 0.6987689\n",
      "generator loss at step 1180: 0.74391615\n",
      "discriminator loss at step 1190: 0.69201547\n",
      "generator loss at step 1190: 0.74612635\n",
      "discriminator loss at step 1200: 0.6962737\n",
      "generator loss at step 1200: 0.73642695\n",
      "discriminator loss at step 1210: 0.6932429\n",
      "generator loss at step 1210: 0.73835385\n",
      "discriminator loss at step 1220: 0.68992984\n",
      "generator loss at step 1220: 0.74486446\n",
      "discriminator loss at step 1230: 0.6938699\n",
      "generator loss at step 1230: 0.74220127\n",
      "discriminator loss at step 1240: 0.6674536\n",
      "generator loss at step 1240: 0.7461093\n",
      "discriminator loss at step 1250: 0.68700296\n",
      "generator loss at step 1250: 0.7394856\n",
      "discriminator loss at step 1260: 0.695097\n",
      "generator loss at step 1260: 0.7433793\n",
      "discriminator loss at step 1270: 0.6954552\n",
      "generator loss at step 1270: 0.74405736\n",
      "discriminator loss at step 1280: 0.6907182\n",
      "generator loss at step 1280: 0.7418364\n",
      "discriminator loss at step 1290: 0.6974405\n",
      "generator loss at step 1290: 0.75013494\n",
      "discriminator loss at step 1300: 0.6916386\n",
      "generator loss at step 1300: 0.7455702\n",
      "discriminator loss at step 1310: 0.685715\n",
      "generator loss at step 1310: 0.7398166\n",
      "discriminator loss at step 1320: 0.6891227\n",
      "generator loss at step 1320: 0.74410135\n",
      "discriminator loss at step 1330: 0.69561154\n",
      "generator loss at step 1330: 0.74642855\n",
      "discriminator loss at step 1340: 0.6940139\n",
      "generator loss at step 1340: 0.7447926\n",
      "discriminator loss at step 1350: 0.68971163\n",
      "generator loss at step 1350: 0.74794036\n",
      "discriminator loss at step 1360: 0.69059193\n",
      "generator loss at step 1360: 0.7438836\n",
      "discriminator loss at step 1370: 0.6890732\n",
      "generator loss at step 1370: 0.7381228\n",
      "discriminator loss at step 1380: 0.6990576\n",
      "generator loss at step 1380: 0.7330038\n",
      "discriminator loss at step 1390: 0.69460905\n",
      "generator loss at step 1390: 0.7414556\n",
      "discriminator loss at step 1400: 0.6909192\n",
      "generator loss at step 1400: 0.7394835\n",
      "discriminator loss at step 1410: 0.69172597\n",
      "generator loss at step 1410: 0.741701\n",
      "discriminator loss at step 1420: 0.69441473\n",
      "generator loss at step 1420: 0.74513894\n",
      "discriminator loss at step 1430: 0.6928921\n",
      "generator loss at step 1430: 0.73586607\n",
      "discriminator loss at step 1440: 0.68899506\n",
      "generator loss at step 1440: 0.7503768\n",
      "discriminator loss at step 1450: 0.6949031\n",
      "generator loss at step 1450: 0.72421724\n",
      "discriminator loss at step 1460: 0.69576645\n",
      "generator loss at step 1460: 0.74622333\n",
      "discriminator loss at step 1470: 0.6986368\n",
      "generator loss at step 1470: 0.7520212\n",
      "discriminator loss at step 1480: 0.6949441\n",
      "generator loss at step 1480: 0.75501657\n",
      "discriminator loss at step 1490: 0.6878324\n",
      "generator loss at step 1490: 0.74700785\n",
      "discriminator loss at step 1500: 0.6929616\n",
      "generator loss at step 1500: 0.74658644\n",
      "discriminator loss at step 1510: 0.6845715\n",
      "generator loss at step 1510: 0.75016165\n",
      "discriminator loss at step 1520: 0.68907297\n",
      "generator loss at step 1520: 0.7589965\n",
      "discriminator loss at step 1530: 0.68927276\n",
      "generator loss at step 1530: 0.7312734\n",
      "discriminator loss at step 1540: 0.6972555\n",
      "generator loss at step 1540: 0.73495746\n",
      "discriminator loss at step 1550: 0.69256514\n",
      "generator loss at step 1550: 0.7372406\n",
      "discriminator loss at step 1560: 0.69009197\n",
      "generator loss at step 1560: 0.7406877\n",
      "discriminator loss at step 1570: 0.6848826\n",
      "generator loss at step 1570: 0.74165606\n",
      "discriminator loss at step 1580: 0.68960845\n",
      "generator loss at step 1580: 0.74575937\n",
      "discriminator loss at step 1590: 0.6887151\n",
      "generator loss at step 1590: 0.7270977\n",
      "discriminator loss at step 1600: 0.68870145\n",
      "generator loss at step 1600: 0.74452674\n",
      "discriminator loss at step 1610: 0.68695974\n",
      "generator loss at step 1610: 0.7380017\n",
      "discriminator loss at step 1620: 0.6931796\n",
      "generator loss at step 1620: 0.74002147\n",
      "discriminator loss at step 1630: 0.695096\n",
      "generator loss at step 1630: 0.7441925\n",
      "discriminator loss at step 1640: 0.69172055\n",
      "generator loss at step 1640: 0.74656224\n",
      "discriminator loss at step 1650: 0.6744434\n",
      "generator loss at step 1650: 0.74230486\n",
      "discriminator loss at step 1660: 0.67863\n",
      "generator loss at step 1660: 0.75746644\n",
      "discriminator loss at step 1670: 0.69780254\n",
      "generator loss at step 1670: 0.74486387\n",
      "discriminator loss at step 1680: 0.6920774\n",
      "generator loss at step 1680: 0.7427339\n",
      "discriminator loss at step 1690: 0.686992\n",
      "generator loss at step 1690: 0.7354533\n",
      "discriminator loss at step 1700: 0.69312155\n",
      "generator loss at step 1700: 0.7492323\n",
      "discriminator loss at step 1710: 0.685361\n",
      "generator loss at step 1710: 0.739914\n",
      "discriminator loss at step 1720: 0.6486807\n",
      "generator loss at step 1720: 0.7429771\n",
      "discriminator loss at step 1730: 0.7175211\n",
      "generator loss at step 1730: 0.74692535\n",
      "discriminator loss at step 1740: 0.6901172\n",
      "generator loss at step 1740: 0.724018\n",
      "discriminator loss at step 1750: 0.7066792\n",
      "generator loss at step 1750: 0.71539134\n",
      "discriminator loss at step 1760: 0.68685985\n",
      "generator loss at step 1760: 0.73398834\n",
      "discriminator loss at step 1770: 0.68862695\n",
      "generator loss at step 1770: 0.75139433\n",
      "discriminator loss at step 1780: 0.69661224\n",
      "generator loss at step 1780: 0.7613245\n",
      "discriminator loss at step 1790: 0.6121001\n",
      "generator loss at step 1790: 0.7584141\n",
      "discriminator loss at step 1800: 0.6731456\n",
      "generator loss at step 1800: 0.76363593\n",
      "discriminator loss at step 1810: 0.69671726\n",
      "generator loss at step 1810: 0.77360165\n",
      "discriminator loss at step 1820: 0.6874525\n",
      "generator loss at step 1820: 0.7583791\n",
      "discriminator loss at step 1830: 0.68276036\n",
      "generator loss at step 1830: 0.7643827\n",
      "discriminator loss at step 1840: 0.68835163\n",
      "generator loss at step 1840: 0.7571179\n",
      "discriminator loss at step 1850: 0.68577325\n",
      "generator loss at step 1850: 0.73744845\n",
      "discriminator loss at step 1860: 0.6452385\n",
      "generator loss at step 1860: 0.6429374\n",
      "discriminator loss at step 1870: 0.67744875\n",
      "generator loss at step 1870: 0.8119024\n",
      "discriminator loss at step 1880: 0.6365481\n",
      "generator loss at step 1880: 0.78212434\n",
      "discriminator loss at step 1890: 0.69800985\n",
      "generator loss at step 1890: 0.7148697\n",
      "discriminator loss at step 1900: 0.6793488\n",
      "generator loss at step 1900: 0.69528013\n",
      "discriminator loss at step 1910: 0.69811857\n",
      "generator loss at step 1910: 0.6805586\n",
      "discriminator loss at step 1920: 0.6829243\n",
      "generator loss at step 1920: 0.7517268\n",
      "discriminator loss at step 1930: 0.66736495\n",
      "generator loss at step 1930: 0.72323304\n",
      "discriminator loss at step 1940: 0.710391\n",
      "generator loss at step 1940: 0.7532574\n",
      "discriminator loss at step 1950: 0.69607306\n",
      "generator loss at step 1950: 0.746992\n",
      "discriminator loss at step 1960: 0.6923234\n",
      "generator loss at step 1960: 0.7405201\n",
      "discriminator loss at step 1970: 0.6858425\n",
      "generator loss at step 1970: 0.7394225\n",
      "discriminator loss at step 1980: 0.67360336\n",
      "generator loss at step 1980: 0.7438868\n",
      "discriminator loss at step 1990: 0.6583313\n",
      "generator loss at step 1990: 0.77789855\n",
      "discriminator loss at step 2000: 0.64166605\n",
      "generator loss at step 2000: 0.739931\n",
      "discriminator loss at step 2010: 0.6549493\n",
      "generator loss at step 2010: 0.8457289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 2020: 0.6874932\n",
      "generator loss at step 2020: 0.77688\n",
      "discriminator loss at step 2030: 0.6798018\n",
      "generator loss at step 2030: 0.75800496\n",
      "discriminator loss at step 2040: 0.68550575\n",
      "generator loss at step 2040: 0.6903578\n",
      "discriminator loss at step 2050: 0.6747263\n",
      "generator loss at step 2050: 0.739214\n",
      "discriminator loss at step 2060: 0.59056807\n",
      "generator loss at step 2060: 0.7082219\n",
      "discriminator loss at step 2070: 0.6991123\n",
      "generator loss at step 2070: 0.80188596\n",
      "discriminator loss at step 2080: 0.68884313\n",
      "generator loss at step 2080: 0.6976617\n",
      "discriminator loss at step 2090: 0.63442373\n",
      "generator loss at step 2090: 0.72825515\n",
      "discriminator loss at step 2100: 0.6174053\n",
      "generator loss at step 2100: 0.74101025\n",
      "discriminator loss at step 2110: 0.61280566\n",
      "generator loss at step 2110: 0.78452957\n",
      "discriminator loss at step 2120: 0.67774886\n",
      "generator loss at step 2120: 0.73418844\n",
      "discriminator loss at step 2130: 0.5854166\n",
      "generator loss at step 2130: 0.85847247\n",
      "discriminator loss at step 2140: 0.74101955\n",
      "generator loss at step 2140: 0.7853154\n",
      "discriminator loss at step 2150: 0.6418333\n",
      "generator loss at step 2150: 0.84885263\n",
      "discriminator loss at step 2160: 0.6479906\n",
      "generator loss at step 2160: 0.8812707\n",
      "discriminator loss at step 2170: 0.54799235\n",
      "generator loss at step 2170: 0.7785572\n",
      "discriminator loss at step 2180: 0.5932539\n",
      "generator loss at step 2180: 0.72834206\n",
      "discriminator loss at step 2190: 0.50326777\n",
      "generator loss at step 2190: 0.79860216\n",
      "discriminator loss at step 2200: 0.4542338\n",
      "generator loss at step 2200: 0.787214\n",
      "discriminator loss at step 2210: 0.91061574\n",
      "generator loss at step 2210: 0.5209526\n",
      "discriminator loss at step 2220: 0.6629809\n",
      "generator loss at step 2220: 0.56421334\n",
      "discriminator loss at step 2230: 0.50782627\n",
      "generator loss at step 2230: 0.74324095\n",
      "discriminator loss at step 2240: 0.49954948\n",
      "generator loss at step 2240: 1.0148212\n",
      "discriminator loss at step 2250: 0.42038336\n",
      "generator loss at step 2250: 0.90416145\n",
      "discriminator loss at step 2260: 0.49935398\n",
      "generator loss at step 2260: 0.78478706\n",
      "discriminator loss at step 2270: 0.43821508\n",
      "generator loss at step 2270: 1.0182638\n",
      "discriminator loss at step 2280: 0.5603897\n",
      "generator loss at step 2280: 1.0486007\n",
      "discriminator loss at step 2290: 0.5050659\n",
      "generator loss at step 2290: 0.955733\n",
      "discriminator loss at step 2300: 0.4118085\n",
      "generator loss at step 2300: 0.9573005\n",
      "discriminator loss at step 2310: 0.38546196\n",
      "generator loss at step 2310: 0.9034721\n",
      "discriminator loss at step 2320: 0.41947302\n",
      "generator loss at step 2320: 0.94218457\n",
      "discriminator loss at step 2330: 0.3030383\n",
      "generator loss at step 2330: 0.89348805\n",
      "discriminator loss at step 2340: 0.5333928\n",
      "generator loss at step 2340: 1.1857338\n",
      "discriminator loss at step 2350: 0.58090365\n",
      "generator loss at step 2350: 0.90490484\n",
      "discriminator loss at step 2360: 0.4016285\n",
      "generator loss at step 2360: 0.99921477\n",
      "discriminator loss at step 2370: 0.2961529\n",
      "generator loss at step 2370: 0.9665167\n",
      "discriminator loss at step 2380: 0.31411314\n",
      "generator loss at step 2380: 0.93574876\n",
      "discriminator loss at step 2390: 0.3698036\n",
      "generator loss at step 2390: 1.1375805\n",
      "discriminator loss at step 2400: 0.33506793\n",
      "generator loss at step 2400: 1.1348128\n",
      "discriminator loss at step 2410: 0.43101186\n",
      "generator loss at step 2410: 0.96604156\n",
      "discriminator loss at step 2420: 0.529239\n",
      "generator loss at step 2420: 0.93090886\n",
      "discriminator loss at step 2430: 0.3928933\n",
      "generator loss at step 2430: 0.867746\n",
      "discriminator loss at step 2440: 0.32739216\n",
      "generator loss at step 2440: 1.0193704\n",
      "discriminator loss at step 2450: 0.33329326\n",
      "generator loss at step 2450: 1.0752634\n",
      "discriminator loss at step 2460: 0.29778132\n",
      "generator loss at step 2460: 0.98990345\n",
      "discriminator loss at step 2470: 0.3023661\n",
      "generator loss at step 2470: 0.96300685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fb57f3d3fbe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_poems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0md_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "batch_size = 5\n",
    "\n",
    "# Start training loop\n",
    "start = 0\n",
    "# Track Losses\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "for step in range(iterations):\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,num_steps, 1))\n",
    "\n",
    "    # Decode them to fake poems\n",
    "    generated_poems = generator.predict(random_latent_vectors)\n",
    "\n",
    "    # Combine them with real poems\n",
    "    stop = start + batch_size\n",
    "    real_poems = x_train[start: stop]\n",
    "    combined_poems = np.concatenate([generated_poems, real_poems])\n",
    "\n",
    "    # Assemble labels discriminating real from fake poems\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    d_loss = discriminator.train_on_batch(combined_poems, labels)\n",
    "    d_losses.append(d_loss)\n",
    "    \n",
    "    # sample random points in the latent space\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size*2, num_steps, 1))\n",
    "\n",
    "    # Assemble labels that say \"all real poems\"\n",
    "    misleading_targets = np.zeros((batch_size*2, 1))\n",
    "\n",
    "    # Train the generator (via the gan model,\n",
    "    # where the discriminator weights are frozen)\n",
    "    g_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "    g_losses.append(g_loss)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        # Save model weights\n",
    "        #gan.save_weights('gan.h5')\n",
    "\n",
    "        # Print metrics\n",
    "        print('discriminator loss at step %s: %s' % (step, d_loss))\n",
    "        print('generator loss at step %s: %s' % (step, g_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb2ec29d30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(g_losses)\n",
    "plt.plot(d_losses)\n",
    "plt.legend(['Gen_loss','Disc_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vector = np.random.normal(size=(1,num_steps, 1))\n",
    "\n",
    "# Decode them to fake poems\n",
    "generated_poem = generator.predict(random_latent_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.8575358e-04, -1.9415155e-02, -3.2703218e-03, ...,\n",
       "        -1.4718541e-02, -2.1906139e-03, -1.6929712e-02],\n",
       "       [ 3.8789891e-04, -2.2236668e-02,  2.3301807e-03, ...,\n",
       "        -2.1957772e-02,  1.4581555e-03, -6.8360684e-03],\n",
       "       [ 1.9202994e-03, -2.7034620e-02,  4.6427529e-03, ...,\n",
       "        -2.9199930e-02,  8.1297792e-03, -4.8007676e-03],\n",
       "       ...,\n",
       "       [ 6.3493466e-01,  5.6074250e-01,  1.8630058e-01, ...,\n",
       "         5.2177477e-01, -3.7874365e-01, -8.1796139e-01],\n",
       "       [ 6.3131809e-01,  5.6201589e-01,  1.8792439e-01, ...,\n",
       "         5.2780575e-01, -3.7630427e-01, -8.1706989e-01],\n",
       "       [ 6.3339984e-01,  5.6165701e-01,  1.9029759e-01, ...,\n",
       "         5.2543670e-01, -3.7873662e-01, -8.1751895e-01]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_poem.reshape(177,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "poem = []\n",
    "dists = []\n",
    "for word in generated_poem[0]:\n",
    "    num = 0\n",
    "    dist = math.inf\n",
    "    for ind, vec in enumerate(embedding_matrix[1:]):\n",
    "        temp = np.linalg.norm(vec-word)\n",
    "        if temp < dist:\n",
    "            dist = temp\n",
    "            num = ind\n",
    "    if num != 0:\n",
    "        poem.append(tokenizer.index_word[num])\n",
    "    else:\n",
    "        poem.append(' ')\n",
    "    dists.append(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eucliean distance at each step apears to gradually increase, suggesting that the network was fairly decent at the earlier stages of the poem but got increasingly more difficult to predict the next word as the poem progressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb2ed019b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dists)\n",
    "plt.legend(['Distance from word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame', 'shame']\n"
     ]
    }
   ],
   "source": [
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
